pub_date	venue	awards	authors	title	citation	url	slug	summary	description
2011-09-22	IEEE Recent Advances in Intelligent Computational Systems		"S. Deivalakshmi, S. Shekkizhar, P. Palanisamy"	"Detection and removal of Salt and Pepper noise in images by improved median filter
"	"@inproceedings{deivalakshmi2011detection,
  title={Detection and removal of salt and pepper noise in images by improved median filter},
  author={Deivalakshmi, S and Sarath, S and Palanisamy, P},
  booktitle={2011 IEEE Recent Advances in Intelligent Computational Systems},
  pages={363--368},
  year={2011},
  organization={IEEE}
}"	https://ieeexplore.ieee.org/abstract/document/6069335	improved-median-filter	A methodology based on median filters for the removal of Salt and Pepper noise by its detection followed by filtering in both binary and gray level images has been proposed in this paper.	A methodology based on median filters for the removal of Salt and Pepper noise by its detection followed by filtering in both binary and gray level images has been proposed in this paper. Linear and nonlinear filters have been proposed earlier for the removal of impulse noise; however the removal of impulse noise often brings about blurring which results in edges being distorted and poor quality. Therefore the necessity to preserve the edges and fine details during filtering is the challenge faced by researchers today. The proposed method consists of noise detection followed by the removal of detected noise by median filter using selective pixels that are not noise themselves. The noise detection is based on simple thresholding of pixels. Computer simulations were carried out to analyse the performance of the proposed method and the results obtained were compared to that of conventional median filter and center weighted median (CWM) filter.
2019-04-23	US Patent Office		"M. Plihal, E. Soltanmohammadi, S. Paramasivam, S. Ravu, A. Jain, S. Shekkizhar, P. Uppaluri"	Optimizing training sets used for setting up inspection-related algorithms	"@misc{plihal2019optimizing,
  title={Optimizing training sets used for setting up inspection-related algorithms},
  author={Plihal, Martin and Soltanmohammadi, Erfan and Paramasivam, Saravanan and Ravu, Sairam and Jain, Ankit and Shekkizhar, Sarath and Uppaluri, Prasanti},
  year={2019},
  month=apr # ""~23"",
  publisher={Google Patents},
  note={US Patent 10,267,748}
}"	https://patents.google.com/patent/US10267748B2/en	optimizing-training	Methods and systems for training an inspection-related algorithm are provided. One system includes one or more computer subsystems configured for performing an initial training of an inspection-related algorithm with a labeled set of defects thereby generating an initial version of the inspection-related algorithm and applying the initial version of the inspection-related algorithm to an unlabeled set of defects.	"Methods and systems for training an inspection-related algorithm are provided. One system includes one or more computer subsystems configured for performing an initial training of an inspection-related algorithm with a labeled set of defects thereby generating an initial version of the inspection-related algorithm and applying the initial version of the inspection-related algorithm to an unlabeled set of defects. The computer subsystem(s) are also configured for altering the labeled set of defects based on results of the applying. The computer subsystem(s) may then iteratively re-train the inspection-related algorithm and alter the labeled set of defects until one or more differences between results produced by a most recent version and a previous version of the algorithm meet one or more criteria. When the one or more differences meet the one or more criteria, the most recent version of the inspection-related algorithm is outputted as the trained algorithm."
2020-05-04	"IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"		"S. Shekkizhar, A. Ortega"	Graph Construction from Data by Non-Negative Kernel Regression	"@inproceedings{shekkizhar2020graph,
  title={Graph Construction from Data by Non-Negative Kernel Regression},
  author={Shekkizhar, Sarath and Ortega, Antonio},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3892--3896},
  year={2020},
  organization={IEEE}
}"	https://ieeexplore.ieee.org/abstract/document/9054425	nnk-graph-icassp	"Data driven graph constructions are often used in machine learning applications. However, learning an optimal graph from data is still a challenging task. K-nearest neighbor and ϵ-neighborhood methods are among the most common graph construction methods, due to their computational simplicity, but the choice of parameters such as K and ϵ associated with these methods is often ad hoc and lacks a clear interpretation."	"Data driven graph constructions are often used in machine learning applications. However, learning an optimal graph from data is still a challenging task. K-nearest neighbor and -neighborhood methods are among the most common graph construction methods, due to their computational simplicity, but the choice of parameters such as K and associated with these methods is often ad hoc and lacks a clear interpretation. The main novelty of this paper is to formulate graph construction as the problem of finding a sparse signal approximation in kernel space, and identifying key similarities between methods in signal approximation and existing graph learning methods. We propose non-negative kernel regression (NNK), an improved approach for graph construction with interesting geometric and theoretical properties. We demonstrate experimentally the efficiency of NNK graphs, their robustness to choice of sparsity K and show that they can outperform state of the art graph methods in semi supervised learning tasks."
2019-10-21	arXiv Preprints		"S. Shekkizhar, A. Ortega"	Graph construction from data using non negative kernel regression (NNK graphs) - Journal draft	"@article{shekkizhar2019graph,
  title={Graph construction from data using non negative kernel regression (NNK graphs)},
  author={Shekkizhar, Sarath and Ortega, Antonio},
  journal={arXiv preprint arXiv:1910.09383},
  year={2019}
}"	https://arxiv.org/abs/1910.09383	nnk-graph-arxiv	"Data driven graph constructions are often used in various applications, including several machine learning tasks, where the goal is to make predictions and discover patterns. However, learning an optimal graph from data is still a challenging task. Weighted K-nearest neighbor and ϵ-neighborhood methods are among the most common graph construction methods, due to their computational simplicity but the choice of parameters such as K and ϵ associated with these methods is often ad hoc and lacks a clear interpretation."	"Data driven graph constructions are often used in various applications, including several machine learning tasks, where the goal is to make predictions and discover patterns. However, learning an optimal graph from data is still a challenging task. Weighted K-nearest neighbor and ϵ-neighborhood methods are among the most common graph construction methods, due to their computational simplicity but the choice of parameters such as K and ϵ associated with these methods is often ad hoc and lacks a clear interpretation. We formulate graph construction as the problem of finding a sparse signal approximation in kernel space, identifying key similarities between methods in signal approximation and existing graph learning methods. We propose non-negative kernel regression~(NNK), an improved approach for graph construction with interesting geometric and theoretical properties. We show experimentally the efficiency of NNK graphs, its robustness to choice of sparsity K and better performance over state of the art graph methods in semi supervised learning tasks on real world data. "
2020-10-25	IEEE International Conference on Image Processing (ICIP)	Best student paper	"S. Shekkizhar, A. Ortega"	Efficient graph construction for image representation	"@article{shekkizhar2020efficient,
  title={Efficient graph construction for image representation},
  author={Shekkizhar, Sarath and Ortega, Antonio},
  journal={arXiv preprint arXiv:2002.06662},
  year={2020}
}"	https://arxiv.org/abs/2002.06662	nnk-image-graph	"Graphs are useful to interpret widely used image processing methods, e.g., bilateral filtering, or to develop new ones, e.g., kernel based techniques. However, simple graph constructions are often used, where edge weight and connectivity depend on a few parameters. In particular, the sparsity of the graph is determined by the choice of a window size."	"Graphs are useful to interpret widely used image processing methods, e.g., bilateral filtering, or to develop new ones, e.g., kernel based techniques. However, simple graph constructions are often used, where edge weight and connectivity depend on a few parameters. In particular, the sparsity of the graph is determined by the choice of a window size. As an alternative, we extend and adapt to images recently introduced non negative kernel regression (NNK) graph construction. In NNK graphs sparsity adapts to intrinsic data properties. Moreover, while previous work considered NNK graphs in generic settings, here we develop novel algorithms that take advantage of image properties so that the NNK approach can scale to large images. Our experiments show that sparse NNK graphs achieve improved energy compaction and denoising performance when compared to using graphs directly derived from the bilateral filter. "
2020-07-20	arXiv Preprints (under review)		"S. Shekkizhar, A. Ortega"	DeepNNK: Explaining deep models and their generalization using polytope interpolation	"@article{shekkizhar2020deepnnk,
  title={DeepNNK: Explaining deep models and their generalization using polytope interpolation},
  author={Shekkizhar, Sarath and Ortega, Antonio},
  journal={arXiv preprint arXiv:2007.10505},
  year={2020}
}"	https://arxiv.org/abs/2007.10505	deepnnk	"Modern machine learning systems based on neural networks have shown great success in learning complex data patterns while being able to make good predictions on unseen data points. However, the limited interpretability of these systems hinders further progress and application to several domains in the real world."	"Modern machine learning systems based on neural networks have shown great success in learning complex data patterns while being able to make good predictions on unseen data points. However, the limited interpretability of these systems hinders further progress and application to several domains in the real world. This predicament is exemplified by time consuming model selection and the difficulties faced in predictive explainability, especially in the presence of adversarial examples. In this paper, we take a step towards better understanding of neural networks by introducing a local polytope interpolation method. The proposed Deep Non Negative Kernel regression (NNK) interpolation framework is non parametric, theoretically simple and geometrically intuitive. We demonstrate instance based explainability for deep learning models and develop a method to identify models with good generalization properties using leave one out estimation. Finally, we draw a rationalization to adversarial and generative examples which are inevitable from an interpolation view of machine learning. "
2020-09-21	IEEE International Workshop on Multimedia Signal Processing (MMSP)		"K. Nonaka, S. Shekkizhar, A. Ortega"	Graph-based Deep Learning Analysis and Instance Selection	"@inproceedings{nonaka2020graph,
  title={Graph-based Deep Learning Analysis and Instance Selection},
  author={Nonaka, Keisuke and Shekkizhar, Sarath and Ortega, Antonio},
  booktitle={MMSP 2020-2020 IEEE International Workshop on Multimedia Signal Processing (MMSP)},
  organization={IEEE}
}"	https://confcats-event-sessions.s3.amazonaws.com/mmsp20/papers/273.pdf	graph-neural-analysis	"While deep learning is a powerful tool for manyapplications, there has been only limited research about selectionof data for training, i.e., instance selection, which enhances deeplearning scalability by saving computational resources."	"While deep learning is a powerful tool for manyapplications, there has been only limited research about selectionof data for training, i.e., instance selection, which enhances deeplearning scalability by saving computational resources. This canbe attributed in part to the difficulty of interpreting deep learningmodels. While some graph-based methods have been proposed toimprove performance and interpret behavior of deep learning,the instance selection problem has not been addressed from agraph perspective. In this paper, we analyze the behavior of deeplearning outputs by using the K-nearest neighbor (KNN) graphconstruction. We observe that when a directed KNN graph isconstructed, instead of the more conventional undirected KNN, alarge number of instances become isolated nodes, i.e., they do notbelong to the directed neighborhoods of any other nodes. Basedon this, we propose two new instance selection methods, that bothlead to fewer isolated nodes, by either directly eliminating them(minimization approach) or by connecting them more stronglyto other points (maximization). Our experiments show that ourproposed maximization method leads to better performance thanrandom selection and recent methods for instance selection."